{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celebA_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eyYPIn006dHUrRqeDfCTojMTKrgunpJf","authorship_tag":"ABX9TyMp7Oh9ckGzPk9UQv1PAzT1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"129f9d75eea440d881ae58c1cee5ec08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_062689e5d6bb47f8b975d1b00419f609","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_618202834f944527b65e433e732ff54d","IPY_MODEL_de7954d213b04fcf97725abf14a8ed71","IPY_MODEL_5fa7ffa692a341ffa4cb2e544ed03833"]}},"062689e5d6bb47f8b975d1b00419f609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"618202834f944527b65e433e732ff54d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e715997cd42b490fb9cfb2288b708c42","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce9a538db7ff41889622cc970f106bda"}},"de7954d213b04fcf97725abf14a8ed71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_440ad58fe0d9489bbda2e96aa05ba019","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":87319819,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":87319819,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e489e13dff894ea1a920b89b4a54facd"}},"5fa7ffa692a341ffa4cb2e544ed03833":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1bbcf4d0fa2d40d28ac12df3905c17a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 83.3M/83.3M [00:00&lt;00:00, 159MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a738a1771ea244e68b027aacea48013e"}},"e715997cd42b490fb9cfb2288b708c42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce9a538db7ff41889622cc970f106bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"440ad58fe0d9489bbda2e96aa05ba019":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e489e13dff894ea1a920b89b4a54facd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bbcf4d0fa2d40d28ac12df3905c17a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a738a1771ea244e68b027aacea48013e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgwE0mnnOHsU","executionInfo":{"status":"ok","timestamp":1633155369828,"user_tz":300,"elapsed":3360,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"3d507669-96be-422c-d39e-1b6d85e8c1e2"},"source":["!pip install barbar"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting barbar\n","  Downloading barbar-0.2.1-py3-none-any.whl (3.9 kB)\n","Installing collected packages: barbar\n","Successfully installed barbar-0.2.1\n"]}]},{"cell_type":"code","metadata":{"id":"lNUhr4p_1PHo","executionInfo":{"status":"ok","timestamp":1633155372678,"user_tz":300,"elapsed":2853,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","import numpy as np\n","from torchvision.datasets import CelebA\n","from torchvision import transforms, models\n","\n","import matplotlib.pyplot as plt\n","\n","import time, copy\n","\n","from barbar import Bar\n","\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XBghDOfY9tn0"},"source":["# Mount drive first"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rScmN72E1Vxs","executionInfo":{"status":"ok","timestamp":1633155372962,"user_tz":300,"elapsed":286,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"5b7c0b93-3a6b-4f4d-d7f1-4fdd2fb31626"},"source":["ls drive/MyDrive/metrics_iclr_2022/celeba/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["identity_CelebA.txt   list_attr_celeba.txt  list_eval_partition.txt\n","img_align_celeba.zip  list_bbox_celeba.txt  list_landmarks_align_celeba.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VNDvUMfU2DYV","executionInfo":{"status":"ok","timestamp":1633155372963,"user_tz":300,"elapsed":7,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"6d4749a3-1d7e-486d-f4ed-7c74d7742040"},"source":["pwd"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"AF_Dxu5P2kM_"},"source":[""]},{"cell_type":"code","metadata":{"id":"8Jsi0sI62ERR","executionInfo":{"status":"ok","timestamp":1633155396864,"user_tz":300,"elapsed":23906,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["cp -r drive/MyDrive/metrics_iclr_2022/celeba/ ."],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFPIAH2z2XjE","executionInfo":{"status":"ok","timestamp":1633155396864,"user_tz":300,"elapsed":10,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"4cfab147-1592-4fb0-d153-cbe28114ea76"},"source":["cd celeba/"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/celeba\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yir97pIP217s","executionInfo":{"status":"ok","timestamp":1633155397128,"user_tz":300,"elapsed":270,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"38b905c9-45cf-46cb-8fa8-b58070dea790"},"source":["ls"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["identity_CelebA.txt   list_attr_celeba.txt  list_eval_partition.txt\n","img_align_celeba.zip  list_bbox_celeba.txt  list_landmarks_align_celeba.txt\n"]}]},{"cell_type":"code","metadata":{"id":"XrQxlpZg27HL","executionInfo":{"status":"ok","timestamp":1633155418111,"user_tz":300,"elapsed":20986,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["!unzip -qq img_align_celeba.zip"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JydRzGeu28o8","executionInfo":{"status":"ok","timestamp":1633155418112,"user_tz":300,"elapsed":10,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"0fe55ba0-f347-40fb-992d-53cfbb24babe"},"source":["cd .."],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oH90xkPZ6rqa","executionInfo":{"status":"ok","timestamp":1633155418112,"user_tz":300,"elapsed":6,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"b99e3a92-102c-48f4-cdce-fa7e40258bcd"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n","train_preprocessing = transforms.Compose([\n","    transforms.RandomSizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","val_preprocessing = transforms.Compose([\n","    transforms.RandomSizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    normalize,\n","])\n","\n","def hair_transform(features):\n","  \"\"\"\n","  creates feature of length 5 (Black_hair, Blond_Hair, Brown_Hair, Gray_Hair, None)\n","  \"\"\"\n","\n","  org_features = features[[8, 9, 11, 17]]\n","  # no hair features set none true\n","  hair_count = torch.count_nonzero(org_features)\n","  if hair_count > 1 :\n","    return torch.tensor(4)\n","  else:\n","    return torch.argmax(org_features, 0)\n","\n","def hair_filter(features):\n","  \"\"\"\n","  creates feature of length 5 (Black_hair, Blond_Hair, Brown_Hair, Gray_Hair, None)\n","  \"\"\"\n","\n","  return torch.count_nonzero(features[[8, 9, 11, 17]])\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:917: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n","  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n"]}]},{"cell_type":"code","metadata":{"id":"mQ9S2LA53OPD","executionInfo":{"status":"ok","timestamp":1633155427558,"user_tz":300,"elapsed":9450,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["celeba = CelebA(root='.', split='all', transform=train_preprocessing, target_transform=hair_transform)\n","#valid_celeba = CelebA(root='.', split='valid', transform=val_preprocessing, target_transform=hair_transform)\n","#test_celeba = CelebA(root='.', split='test', transform=val_preprocessing, target_transform=hair_transform)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjQS6T_0tQg1","executionInfo":{"status":"ok","timestamp":1633155431422,"user_tz":300,"elapsed":3865,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["labels = celeba.attr\n","label_indices = np.arange(len(labels))\n","keep = torch.stack([hair_filter(t) for t in labels], axis=-1)\n","train_idx, val_idx = train_test_split(\n","                  label_indices[keep > 0], \n","                  random_state=42,\n","                  shuffle=True,\n","                  train_size=0.8)\n","\n","train_dataset = Subset(celeba, train_idx)\n","val_dataset = Subset(celeba, val_idx)\n","\n","val_dataset.dataset.transform = val_preprocessing"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-WvnevItM_Z","executionInfo":{"status":"ok","timestamp":1633155431424,"user_tz":300,"elapsed":15,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"9ee07d9a-6eed-4cf7-8152-490083a31bf9"},"source":["\n","dataloaders = {\n","    \"train\": torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4),\n","    \"val\": torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=1),\n","    #\"test\": torch.utils.data.DataLoader(test_celeba, batch_size=512, shuffle=False, num_workers=1),\n","}\n","\n","dataset_sizes = {\n","    \"train\": len(train_dataset),\n","    \"val\": len(val_dataset),\n","    #\"test\": len(test_celeba),\n","}"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"wym7qxv0h33E","executionInfo":{"status":"ok","timestamp":1633155431424,"user_tz":300,"elapsed":12,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["from torch.cuda.amp import autocast, GradScaler\n","scaler = GradScaler()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"QdS1hTf18EYN","executionInfo":{"status":"ok","timestamp":1633155431424,"user_tz":300,"elapsed":12,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}}},"source":["def train_model(model, criterion, dataloaders, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in Bar(dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                  with autocast():\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        scaler.scale(loss).backward()\n","                        #loss.backward()\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        #optimizer.step()\n","\n","                _, preds = torch.max(outputs.detach(), 1)\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Yw3syaV7qZT","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["129f9d75eea440d881ae58c1cee5ec08","062689e5d6bb47f8b975d1b00419f609","618202834f944527b65e433e732ff54d","de7954d213b04fcf97725abf14a8ed71","5fa7ffa692a341ffa4cb2e544ed03833","e715997cd42b490fb9cfb2288b708c42","ce9a538db7ff41889622cc970f106bda","440ad58fe0d9489bbda2e96aa05ba019","e489e13dff894ea1a920b89b4a54facd","1bbcf4d0fa2d40d28ac12df3905c17a5","a738a1771ea244e68b027aacea48013e"]},"executionInfo":{"status":"ok","timestamp":1633155438587,"user_tz":300,"elapsed":7174,"user":{"displayName":"Cody Blakeney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMnw68Xbpqa6XAWqiwTnEROL2on9isaabXWNxq=s64","userId":"06181980365131135747"}},"outputId":"d76dc532-267d-40a8-a76a-5553a648e26d"},"source":["model = models.resnet34(pretrained=True)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 5)\n","\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"129f9d75eea440d881ae58c1cee5ec08","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/83.3M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fui1SLIx-Los","outputId":"e2e0fe39-6a11-4e32-fe0d-a6fb63bcc597"},"source":["model = train_model(model, criterion, dataloaders, optimizer_ft, exp_lr_scheduler,\n","                       num_epochs=25)"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0/24\n","----------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\r   512/100476: [>...............................] - ETA 0.0s"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["100476/100476: [===============================>] - ETA 6.9s\n","train Loss: 0.6619 Acc: 0.7618\n","25120/25120: [===============================>] - ETA 2.2s\n","val Loss: 0.4593 Acc: 0.8415\n","\n","Epoch 1/24\n","----------\n","100476/100476: [===============================>] - ETA 6.5s\n","train Loss: 0.4245 Acc: 0.8541\n","25120/25120: [===============================>] - ETA 2.1s\n","val Loss: 0.4043 Acc: 0.8626\n","\n","Epoch 2/24\n","----------\n","100476/100476: [===============================>] - ETA 6.5s\n","train Loss: 0.3959 Acc: 0.8626\n","25120/25120: [===============================>] - ETA 2.1s\n","val Loss: 0.3912 Acc: 0.8656\n","\n","Epoch 3/24\n","----------\n","100476/100476: [===============================>] - ETA 6.1s\n","train Loss: 0.3796 Acc: 0.8691\n","25120/25120: [===============================>] - ETA 2.1s\n","val Loss: 0.3750 Acc: 0.8719\n","\n","Epoch 4/24\n","----------\n","100476/100476: [===============================>] - ETA 6.3s\n","train Loss: 0.3669 Acc: 0.8738\n"," 1536/25120: [=>..............................] - ETA 101.7s"]}]},{"cell_type":"code","metadata":{"id":"ZJDUln5JGf4J"},"source":["\n","\n","class_names = ['Black_hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', \"combo\"]\n","\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001) \n","\n","def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['train']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                print(preds[j])\n","                ax.set_title('predicted: {}, Actual: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvKoGWheQUP6"},"source":["visualize_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Swy-YtBZT_yx"},"source":[""],"execution_count":null,"outputs":[]}]}